{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPCeYpEh5m+i2GfhyxB/Uoj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neel26desai/cmpe297_assignment2/blob/main/llama_factory/DPO_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRcq008jA-mv",
        "outputId": "5878a8ce-1eae-4c2c-df46-fb7233c4ce7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive\n",
        "%rm -rf LLaMA-Factory\n",
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "%cd LLaMA-Factory\n",
        "%ls\n",
        "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1\n",
        "!pip uninstall -y jax\n",
        "!pip install -e .[torch,bitsandbytes,liger-kernel]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8pykLwZDIwe",
        "outputId": "4d595b4f-5995-4fbd-8a1a-9f226d77fe2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 315, done.\u001b[K\n",
            "remote: Counting objects: 100% (315/315), done.\u001b[K\n",
            "remote: Compressing objects: 100% (245/245), done.\u001b[K\n",
            "remote: Total 315 (delta 80), reused 159 (delta 57), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (315/315), 8.94 MiB | 16.11 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "Updating files: 100% (257/257), done.\n",
            "/content/drive/MyDrive/LLaMA-Factory\n",
            "\u001b[0m\u001b[01;34massets\u001b[0m/       \u001b[01;34mdocker\u001b[0m/      LICENSE      pyproject.toml  requirements.txt  \u001b[01;34msrc\u001b[0m/\n",
            "CITATION.cff  \u001b[01;34mevaluation\u001b[0m/  Makefile     README.md       \u001b[01;34mscripts\u001b[0m/          \u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/         \u001b[01;34mexamples\u001b[0m/    MANIFEST.in  README_zh.md    setup.py\n",
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: torchvision==0.18.1 in /usr/local/lib/python3.10/dist-packages (0.18.1)\n",
            "Requirement already satisfied: torchaudio==2.3.1 in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (9.4.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.68)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "\u001b[33mWARNING: Skipping jax as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mObtaining file:///content/drive/MyDrive/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<=4.45.0,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (4.45.0.dev0)\n",
            "Requirement already satisfied: datasets<=2.21.0,>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.21.0)\n",
            "Requirement already satisfied: accelerate<=0.34.2,>=0.30.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.34.2)\n",
            "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.12.0)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.9.6)\n",
            "Requirement already satisfied: gradio>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (4.44.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.13.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.1.99)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.7.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.20.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.30.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.9.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.114.2)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.1.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.7.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.26.4)\n",
            "Requirement already satisfied: liger-kernel in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.3.0)\n",
            "Requirement already satisfied: bitsandbytes>=0.39.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.43.3)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.3.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.16.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.10.5)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.7.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.10.7)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (9.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.6.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.0.7)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (12.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.9.1.dev0) (0.38.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (2.23.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llamafactory==0.9.1.dev0) (12.6.68)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.1.dev0) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.1.dev0) (0.19.1)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (0.8.10)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.9.1.dev0) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.9.1.dev0) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.9.1.dev0) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.9.1.dev0) (2.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.1.dev0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.3.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (13.8.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (1.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.1.2)\n",
            "Building wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.1.dev0-0.editable-py3-none-any.whl size=22362 sha256=d877c9cdb65a890b598c18484ffb2152265c8953c5f270fc85cc3960eec954e3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kpkx0x60/wheels/7d/56/99/47917bcdf5276670e628f88bc94e50f75d796be2730c20db58\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: llamafactory\n",
            "  Attempting uninstall: llamafactory\n",
            "    Found existing installation: llamafactory 0.9.1.dev0\n",
            "    Uninstalling llamafactory-0.9.1.dev0:\n",
            "      Successfully uninstalled llamafactory-0.9.1.dev0\n",
            "Successfully installed llamafactory-0.9.1.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install liger-kernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0MJ8ITTDfsa",
        "outputId": "bb20f157-2385-4e4d-e4a0-bcfe1dc3c901"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-fzo4b662\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-fzo4b662\n",
            "  Resolved https://github.com/huggingface/transformers to commit 8bd2b1e8c23234cd607ca8d63f53c1edfea27462\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2024.8.30)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9732511 sha256=3632bf0293bc3900549794feedbe9a8ee4b88e6dbb073cba1d0d080cdbca266b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3emg9a8b/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "Successfully installed transformers-4.45.0.dev0\n",
            "Collecting liger-kernel\n",
            "  Downloading liger_kernel-0.3.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from liger-kernel) (2.3.1)\n",
            "Requirement already satisfied: triton>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from liger-kernel) (2.3.1)\n",
            "Requirement already satisfied: transformers>=4.42.0 in /usr/local/lib/python3.10/dist-packages (from liger-kernel) (4.45.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.2->liger-kernel) (12.6.68)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.2->liger-kernel) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.0->liger-kernel) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.0->liger-kernel) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.0->liger-kernel) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.0->liger-kernel) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.2->liger-kernel) (1.3.0)\n",
            "Downloading liger_kernel-0.3.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: liger-kernel\n",
            "Successfully installed liger-kernel-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "try:\n",
        "  assert torch.cuda.is_available() is True\n",
        "except AssertionError:\n",
        "  print(\"Please set up a GPU before using LLaMA Factory: https://medium.com/mlearning-ai/training-yolov4-on-google-colab-316f8fff99c6\")"
      ],
      "metadata": {
        "id": "ljW6pt9tEldp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "%cd /content/drive/MyDrive/LLaMA-Factory\n",
        "\n",
        "NAME = \"Llama-3\"\n",
        "AUTHOR = \"LLaMA Factory\"\n",
        "\n",
        "with open(\"data/identity.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "  dataset = json.load(f)\n",
        "\n",
        "for sample in dataset:\n",
        "  sample[\"output\"] = sample[\"output\"].replace(\"{{\"+ \"name\" + \"}}\", NAME).replace(\"{{\"+ \"author\" + \"}}\", AUTHOR)\n",
        "\n",
        "with open(\"data/identity.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "  json.dump(dataset, f, indent=2, ensure_ascii=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST2iXykJEmU7",
        "outputId": "6b9bc668-6b15-4d86-9493-655fd3fa05ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN2 = userdata.get('HF_TOKEN2')"
      ],
      "metadata": {
        "id": "8G-pCkszEr6J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token $HF_TOKEN2 --add-to-git-credential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51hBl3UtEuVj",
        "outputId": "bf763138-8bf4-4645-b880-1dc921536942"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "args = {\n",
        "    ### model\n",
        "    \"model_name_or_path\": \"Qwen/Qwen2-VL-7B-Instruct\",\n",
        "\n",
        "    ### method\n",
        "    \"stage\": \"dpo\",\n",
        "    \"do_train\": True,\n",
        "    \"finetuning_type\": \"lora\",\n",
        "    \"lora_target\": \"all\",\n",
        "    \"pref_beta\": 0.1,\n",
        "    \"pref_loss\": \"sigmoid\",  # choices: [sigmoid (dpo), orpo, simpo]\n",
        "\n",
        "    ### dataset\n",
        "    \"dataset\": \"rlhf_v\",\n",
        "    \"template\": \"qwen2_vl\",\n",
        "    \"cutoff_len\": 1024,\n",
        "    \"max_samples\": 1000,\n",
        "    \"overwrite_cache\": True,\n",
        "    \"preprocessing_num_workers\": 16,\n",
        "\n",
        "    ### output\n",
        "    \"output_dir\": \"/content/drive/MyDrive/saves/qwen2_vl-7b/lora/dpo\",\n",
        "    \"logging_steps\": 10,\n",
        "    \"save_steps\": 500,\n",
        "    \"plot_loss\": True,\n",
        "    \"overwrite_output_dir\": True,\n",
        "\n",
        "    ### train\n",
        "    \"per_device_train_batch_size\": 1,\n",
        "    \"gradient_accumulation_steps\": 8,\n",
        "    \"learning_rate\": 5.0e-6,\n",
        "    \"num_train_epochs\": 3.0,\n",
        "    \"lr_scheduler_type\": \"cosine\",\n",
        "    \"warmup_ratio\": 0.1,\n",
        "    \"bf16\": True,\n",
        "    \"ddp_timeout\": 180000000,\n",
        "\n",
        "    ### eval\n",
        "    \"val_size\": 0.1,\n",
        "    \"per_device_eval_batch_size\": 1,\n",
        "    \"eval_strategy\": \"steps\",\n",
        "    \"eval_steps\": 500\n",
        "}\n",
        "\n",
        "json.dump(args, open(\"train_llama3.json\", \"w\", encoding=\"utf-8\"), indent=2)\n"
      ],
      "metadata": {
        "id": "rc88vmx0EwOS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/LLaMA-Factory/\n",
        "\n",
        "!llamafactory-cli train train_llama3.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFF2a9D-GzEI",
        "outputId": "d24f5746-8c04-4c80-a701-6358097d305b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LLaMA-Factory\n",
            "2024-09-15 19:24:39.870898: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-09-15 19:24:39.889186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-15 19:24:39.910156: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-15 19:24:39.916704: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-15 19:24:39.932057: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-15 19:24:41.125348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "09/15/2024 19:24:48 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n",
            "config.json: 100% 1.20k/1.20k [00:00<00:00, 7.82MB/s]\n",
            "[INFO|configuration_utils.py:672] 2024-09-15 19:24:48,615 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-09-15 19:24:48,616 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-09-15 19:24:48,618 >> Model config Qwen2VLConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2-VL-7B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3584,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 18944,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 28,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 152064\n",
            "}\n",
            "\n",
            "tokenizer_config.json: 100% 4.19k/4.19k [00:00<00:00, 21.0MB/s]\n",
            "vocab.json: 100% 2.78M/2.78M [00:00<00:00, 4.33MB/s]\n",
            "merges.txt: 100% 1.67M/1.67M [00:00<00:00, 3.86MB/s]\n",
            "tokenizer.json: 100% 7.03M/7.03M [00:00<00:00, 28.3MB/s]\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:52,328 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:52,328 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:52,328 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:52,328 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:52,328 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:52,328 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2479] 2024-09-15 19:24:52,598 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "preprocessor_config.json: 100% 347/347 [00:00<00:00, 2.50MB/s]\n",
            "[INFO|image_processing_base.py:375] 2024-09-15 19:24:53,586 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/preprocessor_config.json\n",
            "[INFO|image_processing_base.py:375] 2024-09-15 19:24:53,823 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/preprocessor_config.json\n",
            "[INFO|image_processing_base.py:429] 2024-09-15 19:24:53,823 >> Image processor Qwen2VLImageProcessor {\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"max_pixels\": 12845056,\n",
            "  \"merge_size\": 2,\n",
            "  \"min_pixels\": 3136,\n",
            "  \"patch_size\": 14,\n",
            "  \"processor_class\": \"Qwen2VLProcessor\",\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"max_pixels\": 12845056,\n",
            "    \"min_pixels\": 3136\n",
            "  },\n",
            "  \"temporal_patch_size\": 2\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:54,077 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:54,078 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:54,078 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:54,078 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:54,078 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2215] 2024-09-15 19:24:54,078 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2479] 2024-09-15 19:24:54,338 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "chat_template.json: 100% 1.05k/1.05k [00:00<00:00, 6.17MB/s]\n",
            "[INFO|processing_utils.py:724] 2024-09-15 19:24:55,410 >> Processor Qwen2VLProcessor:\n",
            "- image_processor: Qwen2VLImageProcessor {\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"max_pixels\": 12845056,\n",
            "  \"merge_size\": 2,\n",
            "  \"min_pixels\": 3136,\n",
            "  \"patch_size\": 14,\n",
            "  \"processor_class\": \"Qwen2VLProcessor\",\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"max_pixels\": 12845056,\n",
            "    \"min_pixels\": 3136\n",
            "  },\n",
            "  \"temporal_patch_size\": 2\n",
            "}\n",
            "\n",
            "- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2-VL-7B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "\n",
            "{\n",
            "  \"processor_class\": \"Qwen2VLProcessor\"\n",
            "}\n",
            "\n",
            "09/15/2024 19:24:55 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
            "09/15/2024 19:24:55 - INFO - llamafactory.data.loader - Loading dataset llamafactory/RLHF-V...\n",
            "Downloading readme: 100% 751/751 [00:00<00:00, 3.15kB/s]\n",
            "Downloading data: 100% 365M/365M [00:01<00:00, 216MB/s]\n",
            "Generating train split: 5733 examples [00:00, 6720.51 examples/s]\n",
            "Converting format of dataset (num_proc=16): 100% 1000/1000 [00:10<00:00, 93.55 examples/s]\n",
            "Running tokenizer on dataset (num_proc=16): 100% 1000/1000 [00:07<00:00, 142.53 examples/s]\n",
            "training example:\n",
            "chosen_input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 3838, 525, 279, 1376, 4419, 498, 22986, 304, 279, 2168, 30, 151645, 198, 151644, 77091, 198, 32, 3908, 883, 11259, 389, 6430, 12233, 264, 4158, 15478, 323, 3691, 24549, 13, 151645]\n",
            "chosen_inputs:\n",
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>What are the key features you observe in the image?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "A young man standing on stage wearing a white shirt and black pants.<|im_end|>\n",
            "chosen_label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 32, 3908, 883, 11259, 389, 6430, 12233, 264, 4158, 15478, 323, 3691, 24549, 13, 151645]\n",
            "chosen_labels:\n",
            "A young man standing on stage wearing a white shirt and black pants.<|im_end|>\n",
            "rejected_input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 3838, 525, 279, 1376, 4419, 498, 22986, 304, 279, 2168, 30, 151645, 198, 151644, 77091, 198, 32, 3908, 883, 11259, 389, 6430, 12233, 4158, 24549, 323, 15294, 13, 151645]\n",
            "rejected_inputs:\n",
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>What are the key features you observe in the image?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "A young man standing on stage wearing white pants and shoes.<|im_end|>\n",
            "rejected_label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 32, 3908, 883, 11259, 389, 6430, 12233, 4158, 24549, 323, 15294, 13, 151645]\n",
            "rejected_labels:\n",
            "A young man standing on stage wearing white pants and shoes.<|im_end|>\n",
            "[INFO|configuration_utils.py:672] 2024-09-15 19:25:21,206 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-09-15 19:25:21,206 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-09-15 19:25:21,208 >> Model config Qwen2VLConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2-VL-7B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3584,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 18944,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 28,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 152064\n",
            "}\n",
            "\n",
            "model.safetensors.index.json: 100% 56.5k/56.5k [00:00<00:00, 96.6MB/s]\n",
            "[INFO|modeling_utils.py:3694] 2024-09-15 19:25:22,260 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/model.safetensors.index.json\n",
            "Downloading shards:   0% 0/5 [00:00<?, ?it/s]\n",
            "model-00001-of-00005.safetensors:   0% 0.00/3.90G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   0% 10.5M/3.90G [00:00<01:24, 46.0MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   2% 62.9M/3.90G [00:00<00:17, 220MB/s] \u001b[A\n",
            "model-00001-of-00005.safetensors:   3% 115M/3.90G [00:00<00:12, 314MB/s] \u001b[A\n",
            "model-00001-of-00005.safetensors:   4% 168M/3.90G [00:00<00:10, 372MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   6% 231M/3.90G [00:00<00:08, 434MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   8% 294M/3.90G [00:00<00:07, 473MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   9% 357M/3.90G [00:00<00:07, 499MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  11% 419M/3.90G [00:01<00:06, 515MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  12% 482M/3.90G [00:01<00:06, 526MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  14% 545M/3.90G [00:01<00:06, 535MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  16% 608M/3.90G [00:01<00:06, 515MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  17% 661M/3.90G [00:01<00:06, 508MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  18% 713M/3.90G [00:01<00:06, 503MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  20% 765M/3.90G [00:01<00:06, 500MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  21% 828M/3.90G [00:01<00:06, 509MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  23% 881M/3.90G [00:01<00:05, 513MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  24% 944M/3.90G [00:02<00:05, 518MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  26% 996M/3.90G [00:02<00:05, 505MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  27% 1.05G/3.90G [00:02<00:05, 501MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  28% 1.10G/3.90G [00:02<00:05, 502MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  30% 1.16G/3.90G [00:02<00:05, 516MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  31% 1.22G/3.90G [00:02<00:05, 518MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  33% 1.27G/3.90G [00:02<00:05, 517MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  34% 1.32G/3.90G [00:02<00:05, 514MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  35% 1.37G/3.90G [00:02<00:04, 514MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  37% 1.43G/3.90G [00:02<00:04, 516MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  38% 1.49G/3.90G [00:03<00:04, 520MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  40% 1.54G/3.90G [00:03<00:04, 521MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  41% 1.59G/3.90G [00:03<00:04, 521MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  42% 1.66G/3.90G [00:03<00:04, 529MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  44% 1.72G/3.90G [00:03<00:04, 527MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  46% 1.78G/3.90G [00:03<00:04, 525MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  47% 1.85G/3.90G [00:03<00:03, 524MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  49% 1.90G/3.90G [00:03<00:03, 524MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  50% 1.96G/3.90G [00:03<00:03, 526MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  52% 2.02G/3.90G [00:04<00:04, 424MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  53% 2.08G/3.90G [00:04<00:04, 437MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  55% 2.13G/3.90G [00:04<00:04, 421MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  56% 2.18G/3.90G [00:04<00:04, 401MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  57% 2.22G/3.90G [00:04<00:04, 351MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  58% 2.26G/3.90G [00:04<00:04, 355MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  59% 2.31G/3.90G [00:05<00:04, 340MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  61% 2.36G/3.90G [00:05<00:04, 367MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  62% 2.41G/3.90G [00:05<00:03, 389MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  63% 2.46G/3.90G [00:05<00:03, 405MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  64% 2.51G/3.90G [00:05<00:03, 398MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  65% 2.55G/3.90G [00:05<00:04, 333MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  67% 2.60G/3.90G [00:05<00:03, 360MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  68% 2.64G/3.90G [00:05<00:03, 373MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  69% 2.69G/3.90G [00:05<00:03, 398MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  70% 2.75G/3.90G [00:06<00:02, 418MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  72% 2.80G/3.90G [00:06<00:03, 333MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  73% 2.84G/3.90G [00:06<00:03, 350MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  74% 2.89G/3.90G [00:06<00:02, 374MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  76% 2.95G/3.90G [00:06<00:02, 401MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  77% 3.00G/3.90G [00:06<00:02, 418MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  78% 3.05G/3.90G [00:06<00:01, 430MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  80% 3.10G/3.90G [00:07<00:02, 373MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  81% 3.16G/3.90G [00:07<00:01, 388MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  82% 3.21G/3.90G [00:07<00:01, 393MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  83% 3.25G/3.90G [00:07<00:01, 393MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  84% 3.29G/3.90G [00:07<00:01, 375MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  86% 3.33G/3.90G [00:07<00:01, 363MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  87% 3.39G/3.90G [00:07<00:01, 386MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  88% 3.43G/3.90G [00:10<00:07, 61.2MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  89% 3.48G/3.90G [00:10<00:04, 85.7MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  91% 3.53G/3.90G [00:10<00:03, 116MB/s] \u001b[A\n",
            "model-00001-of-00005.safetensors:  92% 3.59G/3.90G [00:10<00:02, 152MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  93% 3.64G/3.90G [00:10<00:01, 191MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  95% 3.69G/3.90G [00:10<00:00, 233MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  96% 3.74G/3.90G [00:10<00:00, 274MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  97% 3.80G/3.90G [00:10<00:00, 312MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  99% 3.85G/3.90G [00:10<00:00, 347MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors: 100% 3.90G/3.90G [00:11<00:00, 353MB/s]\n",
            "Downloading shards:  20% 1/5 [00:11<00:46, 11.50s/it]\n",
            "model-00002-of-00005.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   0% 10.5M/3.86G [00:00<01:21, 47.2MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   2% 73.4M/3.86G [00:00<00:14, 256MB/s] \u001b[A\n",
            "model-00002-of-00005.safetensors:   3% 126M/3.86G [00:00<00:10, 347MB/s] \u001b[A\n",
            "model-00002-of-00005.safetensors:   5% 189M/3.86G [00:00<00:08, 416MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   7% 252M/3.86G [00:00<00:07, 459MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   8% 304M/3.86G [00:00<00:07, 477MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   9% 357M/3.86G [00:00<00:07, 486MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  11% 409M/3.86G [00:00<00:07, 482MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  12% 461M/3.86G [00:01<00:06, 486MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  13% 514M/3.86G [00:01<00:06, 492MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  15% 566M/3.86G [00:01<00:06, 497MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  16% 619M/3.86G [00:01<00:06, 496MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  17% 671M/3.86G [00:01<00:06, 502MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  19% 724M/3.86G [00:01<00:06, 499MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  20% 776M/3.86G [00:01<00:06, 498MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  21% 828M/3.86G [00:01<00:06, 497MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  23% 881M/3.86G [00:01<00:06, 489MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  24% 933M/3.86G [00:02<00:06, 479MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  26% 986M/3.86G [00:02<00:06, 470MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  27% 1.04G/3.86G [00:02<00:05, 472MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  28% 1.09G/3.86G [00:02<00:05, 467MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  30% 1.14G/3.86G [00:02<00:05, 464MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  31% 1.20G/3.86G [00:02<00:05, 459MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  32% 1.25G/3.86G [00:02<00:05, 455MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  34% 1.30G/3.86G [00:02<00:05, 452MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  35% 1.35G/3.86G [00:02<00:05, 451MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  36% 1.41G/3.86G [00:03<00:05, 451MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  38% 1.46G/3.86G [00:03<00:05, 440MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  39% 1.51G/3.86G [00:03<00:05, 461MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  40% 1.56G/3.86G [00:03<00:04, 473MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  42% 1.61G/3.86G [00:03<00:06, 353MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  43% 1.67G/3.86G [00:03<00:05, 391MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  44% 1.72G/3.86G [00:03<00:05, 423MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  46% 1.77G/3.86G [00:03<00:04, 443MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  47% 1.82G/3.86G [00:04<00:04, 450MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  49% 1.88G/3.86G [00:04<00:05, 367MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  50% 1.92G/3.86G [00:04<00:05, 328MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  51% 1.97G/3.86G [00:04<00:05, 371MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  53% 2.03G/3.86G [00:04<00:04, 415MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  54% 2.09G/3.86G [00:04<00:04, 396MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  55% 2.14G/3.86G [00:04<00:04, 412MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  57% 2.19G/3.86G [00:05<00:03, 422MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  58% 2.24G/3.86G [00:05<00:03, 447MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  59% 2.30G/3.86G [00:05<00:03, 437MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  61% 2.35G/3.86G [00:05<00:03, 404MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  62% 2.39G/3.86G [00:05<00:04, 318MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  63% 2.43G/3.86G [00:05<00:05, 268MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  64% 2.46G/3.86G [00:05<00:05, 269MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  65% 2.51G/3.86G [00:06<00:04, 292MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  66% 2.57G/3.86G [00:06<00:03, 357MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  68% 2.61G/3.86G [00:06<00:03, 350MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  69% 2.65G/3.86G [00:06<00:03, 335MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  70% 2.69G/3.86G [00:06<00:03, 301MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  71% 2.74G/3.86G [00:06<00:03, 292MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  72% 2.77G/3.86G [00:06<00:03, 284MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  72% 2.80G/3.86G [00:07<00:03, 277MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  73% 2.83G/3.86G [00:07<00:03, 271MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  74% 2.86G/3.86G [00:07<00:03, 261MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  75% 2.89G/3.86G [00:07<00:03, 255MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  76% 2.93G/3.86G [00:07<00:03, 249MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  77% 2.96G/3.86G [00:07<00:03, 240MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  77% 2.99G/3.86G [00:07<00:03, 233MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  78% 3.02G/3.86G [00:08<00:03, 226MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  79% 3.05G/3.86G [00:08<00:03, 219MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  80% 3.08G/3.86G [00:08<00:03, 211MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  81% 3.11G/3.86G [00:08<00:03, 211MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  81% 3.15G/3.86G [00:08<00:03, 217MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  82% 3.19G/3.86G [00:08<00:02, 256MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  84% 3.24G/3.86G [00:08<00:01, 320MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  85% 3.29G/3.86G [00:08<00:01, 370MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  87% 3.34G/3.86G [00:09<00:01, 409MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  88% 3.40G/3.86G [00:09<00:01, 440MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  89% 3.45G/3.86G [00:09<00:00, 462MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  91% 3.50G/3.86G [00:09<00:00, 477MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  92% 3.55G/3.86G [00:09<00:00, 443MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  93% 3.61G/3.86G [00:09<00:00, 461MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  95% 3.66G/3.86G [00:09<00:00, 475MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  96% 3.72G/3.86G [00:09<00:00, 495MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  98% 3.77G/3.86G [00:09<00:00, 494MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors: 100% 3.86G/3.86G [00:10<00:00, 383MB/s]\n",
            "Downloading shards:  40% 2/5 [00:22<00:32, 10.94s/it]\n",
            "model-00003-of-00005.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   1% 52.4M/3.86G [00:00<00:07, 519MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   3% 115M/3.86G [00:00<00:07, 531MB/s] \u001b[A\n",
            "model-00003-of-00005.safetensors:   5% 178M/3.86G [00:00<00:06, 530MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   6% 241M/3.86G [00:00<00:06, 521MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   8% 294M/3.86G [00:00<00:06, 516MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   9% 346M/3.86G [00:00<00:06, 512MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  10% 398M/3.86G [00:00<00:06, 514MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  12% 461M/3.86G [00:00<00:06, 524MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  14% 524M/3.86G [00:01<00:06, 526MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  15% 587M/3.86G [00:01<00:06, 512MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  17% 640M/3.86G [00:01<00:06, 505MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  18% 692M/3.86G [00:01<00:06, 507MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  19% 744M/3.86G [00:01<00:06, 505MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  21% 797M/3.86G [00:01<00:06, 504MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  22% 849M/3.86G [00:01<00:05, 507MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  24% 912M/3.86G [00:01<00:05, 523MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  25% 975M/3.86G [00:01<00:05, 534MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  27% 1.04G/3.86G [00:02<00:08, 346MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  28% 1.10G/3.86G [00:02<00:07, 387MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  30% 1.16G/3.86G [00:02<00:06, 421MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  31% 1.22G/3.86G [00:02<00:05, 444MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  33% 1.28G/3.86G [00:02<00:05, 468MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  34% 1.33G/3.86G [00:02<00:05, 477MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  36% 1.38G/3.86G [00:02<00:05, 486MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  37% 1.44G/3.86G [00:02<00:04, 491MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  39% 1.50G/3.86G [00:03<00:04, 505MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  40% 1.56G/3.86G [00:03<00:04, 508MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  42% 1.61G/3.86G [00:03<00:04, 506MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  43% 1.68G/3.86G [00:03<00:04, 515MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  45% 1.73G/3.86G [00:03<00:04, 513MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  46% 1.78G/3.86G [00:03<00:04, 505MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  47% 1.84G/3.86G [00:03<00:04, 505MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  49% 1.89G/3.86G [00:03<00:03, 504MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  50% 1.94G/3.86G [00:04<00:04, 435MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  52% 2.00G/3.86G [00:04<00:03, 467MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  53% 2.06G/3.86G [00:04<00:04, 400MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  55% 2.11G/3.86G [00:04<00:04, 423MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  56% 2.16G/3.86G [00:04<00:03, 448MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  57% 2.21G/3.86G [00:04<00:03, 427MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  59% 2.26G/3.86G [00:04<00:03, 430MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  60% 2.32G/3.86G [00:04<00:03, 422MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  61% 2.37G/3.86G [00:05<00:04, 304MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  63% 2.42G/3.86G [00:05<00:04, 343MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  64% 2.47G/3.86G [00:05<00:03, 374MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  65% 2.53G/3.86G [00:05<00:03, 382MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  66% 2.57G/3.86G [00:05<00:03, 366MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  68% 2.63G/3.86G [00:05<00:03, 391MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  69% 2.67G/3.86G [00:06<00:03, 304MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  70% 2.72G/3.86G [00:06<00:04, 261MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  72% 2.77G/3.86G [00:06<00:03, 309MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  73% 2.82G/3.86G [00:06<00:03, 346MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  74% 2.87G/3.86G [00:06<00:02, 381MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  76% 2.94G/3.86G [00:06<00:02, 426MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  78% 3.00G/3.86G [00:06<00:01, 458MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  79% 3.05G/3.86G [00:07<00:02, 371MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  80% 3.10G/3.86G [00:07<00:01, 403MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  82% 3.16G/3.86G [00:07<00:01, 431MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  83% 3.21G/3.86G [00:07<00:01, 452MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  84% 3.26G/3.86G [00:07<00:01, 458MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  86% 3.31G/3.86G [00:07<00:01, 467MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  87% 3.37G/3.86G [00:07<00:01, 336MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  88% 3.42G/3.86G [00:07<00:01, 374MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  90% 3.47G/3.86G [00:08<00:00, 407MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  91% 3.52G/3.86G [00:08<00:00, 370MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  93% 3.58G/3.86G [00:08<00:00, 396MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  94% 3.63G/3.86G [00:08<00:00, 387MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  95% 3.68G/3.86G [00:08<00:00, 412MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  97% 3.73G/3.86G [00:08<00:00, 385MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  98% 3.77G/3.86G [00:08<00:00, 287MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors: 100% 3.86G/3.86G [00:09<00:00, 423MB/s]\n",
            "Downloading shards:  60% 3/5 [00:32<00:21, 10.53s/it]\n",
            "model-00004-of-00005.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   1% 52.4M/3.86G [00:00<00:08, 465MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   3% 105M/3.86G [00:00<00:07, 478MB/s] \u001b[A\n",
            "model-00004-of-00005.safetensors:   4% 157M/3.86G [00:00<00:07, 474MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   5% 210M/3.86G [00:00<00:08, 447MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   7% 262M/3.86G [00:00<00:08, 438MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   8% 315M/3.86G [00:00<00:08, 441MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   9% 367M/3.86G [00:00<00:07, 445MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  11% 419M/3.86G [00:00<00:07, 448MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  12% 472M/3.86G [00:01<00:07, 449MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  14% 524M/3.86G [00:01<00:07, 443MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  15% 577M/3.86G [00:01<00:07, 442MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  16% 629M/3.86G [00:01<00:07, 461MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  18% 682M/3.86G [00:01<00:06, 458MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  19% 734M/3.86G [00:01<00:06, 453MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  21% 797M/3.86G [00:01<00:06, 481MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  22% 849M/3.86G [00:01<00:06, 489MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  23% 902M/3.86G [00:01<00:05, 495MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  25% 954M/3.86G [00:02<00:05, 489MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  26% 1.01G/3.86G [00:02<00:05, 491MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  27% 1.06G/3.86G [00:02<00:05, 493MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  29% 1.12G/3.86G [00:02<00:05, 457MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  30% 1.17G/3.86G [00:02<00:06, 421MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  32% 1.23G/3.86G [00:02<00:07, 357MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  33% 1.28G/3.86G [00:02<00:06, 381MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  34% 1.33G/3.86G [00:02<00:06, 411MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  36% 1.38G/3.86G [00:03<00:05, 435MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  37% 1.44G/3.86G [00:03<00:05, 407MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  39% 1.49G/3.86G [00:03<00:06, 393MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  40% 1.54G/3.86G [00:03<00:05, 397MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  41% 1.58G/3.86G [00:03<00:07, 314MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  42% 1.63G/3.86G [00:03<00:06, 321MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  43% 1.67G/3.86G [00:04<00:07, 290MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  44% 1.70G/3.86G [00:04<00:08, 270MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  45% 1.73G/3.86G [00:04<00:08, 247MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  46% 1.76G/3.86G [00:04<00:09, 225MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  47% 1.81G/3.86G [00:04<00:07, 274MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  48% 1.86G/3.86G [00:04<00:06, 303MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  49% 1.90G/3.86G [00:04<00:06, 322MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  50% 1.94G/3.86G [00:04<00:05, 326MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  51% 1.98G/3.86G [00:05<00:05, 338MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  52% 2.02G/3.86G [00:05<00:05, 337MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  53% 2.07G/3.86G [00:05<00:05, 328MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  55% 2.11G/3.86G [00:05<00:05, 329MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  56% 2.15G/3.86G [00:05<00:05, 315MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  57% 2.19G/3.86G [00:05<00:05, 308MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  58% 2.22G/3.86G [00:05<00:05, 295MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  58% 2.25G/3.86G [00:06<00:05, 283MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  59% 2.29G/3.86G [00:06<00:05, 270MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  60% 2.32G/3.86G [00:06<00:06, 255MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  61% 2.35G/3.86G [00:06<00:06, 252MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  62% 2.38G/3.86G [00:06<00:05, 257MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  63% 2.43G/3.86G [00:06<00:04, 313MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  64% 2.49G/3.86G [00:06<00:03, 360MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  66% 2.54G/3.86G [00:06<00:03, 389MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  67% 2.59G/3.86G [00:06<00:03, 420MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  68% 2.64G/3.86G [00:07<00:02, 438MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  70% 2.69G/3.86G [00:07<00:02, 459MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  71% 2.75G/3.86G [00:07<00:02, 472MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  72% 2.80G/3.86G [00:07<00:02, 482MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  74% 2.85G/3.86G [00:07<00:02, 469MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  75% 2.90G/3.86G [00:07<00:02, 461MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  77% 2.96G/3.86G [00:07<00:01, 465MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  78% 3.01G/3.86G [00:07<00:01, 472MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  79% 3.06G/3.86G [00:07<00:01, 471MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  81% 3.11G/3.86G [00:08<00:01, 482MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  82% 3.18G/3.86G [00:08<00:01, 496MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  84% 3.23G/3.86G [00:08<00:01, 503MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  85% 3.28G/3.86G [00:08<00:01, 482MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  86% 3.33G/3.86G [00:08<00:01, 478MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  88% 3.40G/3.86G [00:08<00:00, 494MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  90% 3.46G/3.86G [00:08<00:00, 505MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  91% 3.51G/3.86G [00:08<00:00, 404MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  92% 3.57G/3.86G [00:09<00:00, 377MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  93% 3.61G/3.86G [00:09<00:00, 359MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  94% 3.65G/3.86G [00:09<00:00, 348MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  96% 3.69G/3.86G [00:09<00:00, 327MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  97% 3.73G/3.86G [00:09<00:00, 313MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  98% 3.77G/3.86G [00:09<00:00, 302MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  98% 3.81G/3.86G [00:09<00:00, 292MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors: 100% 3.86G/3.86G [00:10<00:00, 378MB/s]\n",
            "Downloading shards:  80% 4/5 [00:42<00:10, 10.64s/it]\n",
            "model-00005-of-00005.safetensors:   0% 0.00/1.09G [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:   5% 52.4M/1.09G [00:00<00:02, 446MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  10% 105M/1.09G [00:00<00:02, 455MB/s] \u001b[A\n",
            "model-00005-of-00005.safetensors:  14% 157M/1.09G [00:00<00:02, 431MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  19% 210M/1.09G [00:00<00:02, 413MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  24% 262M/1.09G [00:00<00:01, 424MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  29% 315M/1.09G [00:00<00:01, 421MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  34% 367M/1.09G [00:00<00:01, 432MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  38% 419M/1.09G [00:00<00:01, 439MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  43% 472M/1.09G [00:01<00:01, 443MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  48% 524M/1.09G [00:01<00:01, 447MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  53% 577M/1.09G [00:01<00:01, 452MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  58% 629M/1.09G [00:01<00:01, 457MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  63% 682M/1.09G [00:01<00:00, 455MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  67% 734M/1.09G [00:01<00:00, 451MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  72% 786M/1.09G [00:01<00:00, 454MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  77% 839M/1.09G [00:01<00:00, 451MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  82% 891M/1.09G [00:02<00:00, 458MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  87% 944M/1.09G [00:02<00:00, 459MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  91% 996M/1.09G [00:02<00:00, 456MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors: 100% 1.09G/1.09G [00:02<00:00, 445MB/s]\n",
            "Downloading shards: 100% 5/5 [00:45<00:00,  9.17s/it]\n",
            "[INFO|modeling_utils.py:1613] 2024-09-15 19:26:08,088 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1097] 2024-09-15 19:26:08,089 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645\n",
            "}\n",
            "\n",
            "[WARNING|logging.py:328] 2024-09-15 19:26:08,113 >> `Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
            "Loading checkpoint shards: 100% 5/5 [00:06<00:00,  1.38s/it]\n",
            "[INFO|modeling_utils.py:4526] 2024-09-15 19:26:15,147 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:4534] 2024-09-15 19:26:15,147 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2-VL-7B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.\n",
            "generation_config.json: 100% 244/244 [00:00<00:00, 1.76MB/s]\n",
            "[INFO|configuration_utils.py:1052] 2024-09-15 19:26:15,662 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/generation_config.json\n",
            "[INFO|configuration_utils.py:1097] 2024-09-15 19:26:15,662 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"temperature\": 0.01,\n",
            "  \"top_k\": 1,\n",
            "  \"top_p\": 0.001\n",
            "}\n",
            "\n",
            "09/15/2024 19:26:15 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
            "09/15/2024 19:26:15 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
            "09/15/2024 19:26:15 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
            "09/15/2024 19:26:15 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
            "09/15/2024 19:26:15 - INFO - llamafactory.model.model_utils.misc - Found linear modules: o_proj,k_proj,gate_proj,down_proj,up_proj,q_proj,v_proj\n",
            "09/15/2024 19:26:16 - INFO - llamafactory.model.loader - trainable params: 20,185,088 || all params: 8,311,560,704 || trainable%: 0.2429\n",
            "[INFO|trainer.py:668] 2024-09-15 19:26:16,926 >> Using auto half precision backend\n",
            "[INFO|trainer.py:2213] 2024-09-15 19:26:17,360 >> ***** Running training *****\n",
            "[INFO|trainer.py:2214] 2024-09-15 19:26:17,361 >>   Num examples = 900\n",
            "[INFO|trainer.py:2215] 2024-09-15 19:26:17,361 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2216] 2024-09-15 19:26:17,361 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:2219] 2024-09-15 19:26:17,361 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:2220] 2024-09-15 19:26:17,361 >>   Gradient Accumulation steps = 8\n",
            "[INFO|trainer.py:2221] 2024-09-15 19:26:17,361 >>   Total optimization steps = 336\n",
            "[INFO|trainer.py:2222] 2024-09-15 19:26:17,366 >>   Number of trainable parameters = 20,185,088\n",
            "{'loss': 0.6934, 'grad_norm': 1.3429208993911743, 'learning_rate': 1.4705882352941177e-06, 'rewards/chosen': -0.0007146935095079243, 'rewards/rejected': -0.0007100192597135901, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -4.674587216868531e-06, 'logps/rejected': -124.40169525146484, 'logps/chosen': -150.90798950195312, 'logits/rejected': -2.505267381668091, 'logits/chosen': -2.4646108150482178, 'epoch': 0.09}\n",
            "{'loss': 0.6906, 'grad_norm': 1.577802300453186, 'learning_rate': 2.9411764705882355e-06, 'rewards/chosen': 0.00238048960454762, 'rewards/rejected': -0.003329309867694974, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': 0.005709798075258732, 'logps/rejected': -165.1649627685547, 'logps/chosen': -180.8066864013672, 'logits/rejected': -2.526660680770874, 'logits/chosen': -2.5017504692077637, 'epoch': 0.18}\n",
            "{'loss': 0.6914, 'grad_norm': 2.0938608646392822, 'learning_rate': 4.411764705882353e-06, 'rewards/chosen': -0.003369858954101801, 'rewards/rejected': -0.007780477404594421, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': 0.0044106184504926205, 'logps/rejected': -140.25753784179688, 'logps/chosen': -168.08425903320312, 'logits/rejected': -2.4803109169006348, 'logits/chosen': -2.4219985008239746, 'epoch': 0.27}\n",
            "{'loss': 0.6938, 'grad_norm': 1.944484829902649, 'learning_rate': 4.995131923687488e-06, 'rewards/chosen': -0.0007143508410081267, 'rewards/rejected': 0.0001670941710472107, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': -0.0008814450120553374, 'logps/rejected': -133.72203063964844, 'logps/chosen': -151.65744018554688, 'logits/rejected': -2.458343029022217, 'logits/chosen': -2.4039199352264404, 'epoch': 0.36}\n",
            "{'loss': 0.6875, 'grad_norm': 1.0156751871109009, 'learning_rate': 4.965451197130373e-06, 'rewards/chosen': 0.012139948084950447, 'rewards/rejected': -2.1744519472122192e-05, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.012161691673099995, 'logps/rejected': -128.85240173339844, 'logps/chosen': -147.6046600341797, 'logits/rejected': -2.4803099632263184, 'logits/chosen': -2.443613290786743, 'epoch': 0.44}\n",
            "{'loss': 0.6836, 'grad_norm': 2.3148081302642822, 'learning_rate': 4.90911473983908e-06, 'rewards/chosen': 0.016648728400468826, 'rewards/rejected': -0.002946221036836505, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.0195949487388134, 'logps/rejected': -128.33010864257812, 'logps/chosen': -143.72181701660156, 'logits/rejected': -2.5090675354003906, 'logits/chosen': -2.4725873470306396, 'epoch': 0.53}\n",
            "{'loss': 0.686, 'grad_norm': 1.8421211242675781, 'learning_rate': 4.826731644963705e-06, 'rewards/chosen': 0.016249507665634155, 'rewards/rejected': 0.0010837512090802193, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.015165758319199085, 'logps/rejected': -143.20968627929688, 'logps/chosen': -162.0642852783203, 'logits/rejected': -2.4684064388275146, 'logits/chosen': -2.429530382156372, 'epoch': 0.62}\n",
            "{'loss': 0.6894, 'grad_norm': 1.4924699068069458, 'learning_rate': 4.71919261421297e-06, 'rewards/chosen': 0.00968238990753889, 'rewards/rejected': 0.0013444169890135527, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.00833797361701727, 'logps/rejected': -122.78072357177734, 'logps/chosen': -133.50448608398438, 'logits/rejected': -2.396388292312622, 'logits/chosen': -2.3625643253326416, 'epoch': 0.71}\n",
            "{'loss': 0.674, 'grad_norm': 1.5515276193618774, 'learning_rate': 4.587660327850203e-06, 'rewards/chosen': 0.022053292021155357, 'rewards/rejected': -0.01798832230269909, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.040041618049144745, 'logps/rejected': -122.0870132446289, 'logps/chosen': -140.06640625, 'logits/rejected': -2.4633374214172363, 'logits/chosen': -2.4073352813720703, 'epoch': 0.8}\n",
            "{'loss': 0.6683, 'grad_norm': 2.0130412578582764, 'learning_rate': 4.43355687413747e-06, 'rewards/chosen': 0.0504835844039917, 'rewards/rejected': -0.001932893879711628, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.05241648107767105, 'logps/rejected': -119.95353698730469, 'logps/chosen': -135.57473754882812, 'logits/rejected': -2.4560985565185547, 'logits/chosen': -2.4032397270202637, 'epoch': 0.89}\n",
            "{'loss': 0.6619, 'grad_norm': 2.0078799724578857, 'learning_rate': 4.258548374136976e-06, 'rewards/chosen': 0.08788762986660004, 'rewards/rejected': 0.020980793982744217, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.06690683215856552, 'logps/rejected': -145.81007385253906, 'logps/chosen': -160.0089874267578, 'logits/rejected': -2.4595913887023926, 'logits/chosen': -2.4191083908081055, 'epoch': 0.98}\n",
            "{'loss': 0.6461, 'grad_norm': 1.1682283878326416, 'learning_rate': 4.064526968101844e-06, 'rewards/chosen': 0.1117437332868576, 'rewards/rejected': 0.008154025301337242, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.10358969867229462, 'logps/rejected': -122.94954681396484, 'logps/chosen': -141.50123596191406, 'logits/rejected': -2.4848694801330566, 'logits/chosen': -2.4435853958129883, 'epoch': 1.07}\n",
            "{'loss': 0.6159, 'grad_norm': 1.810028314590454, 'learning_rate': 3.853590358214119e-06, 'rewards/chosen': 0.13244280219078064, 'rewards/rejected': -0.03719665855169296, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 0.1696394681930542, 'logps/rejected': -133.66323852539062, 'logps/chosen': -150.98342895507812, 'logits/rejected': -2.4530398845672607, 'logits/chosen': -2.4098246097564697, 'epoch': 1.16}\n",
            "{'loss': 0.6194, 'grad_norm': 2.2308013439178467, 'learning_rate': 3.6280191288478437e-06, 'rewards/chosen': 0.09840743243694305, 'rewards/rejected': -0.06703206896781921, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.16543950140476227, 'logps/rejected': -109.28593444824219, 'logps/chosen': -123.6678237915039, 'logits/rejected': -2.5409955978393555, 'logits/chosen': -2.498795986175537, 'epoch': 1.24}\n",
            "{'loss': 0.5891, 'grad_norm': 2.123948574066162, 'learning_rate': 3.3902520895638674e-06, 'rewards/chosen': 0.22225138545036316, 'rewards/rejected': -0.012629330158233643, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 0.2348807156085968, 'logps/rejected': -146.43869018554688, 'logps/chosen': -158.81515502929688, 'logits/rejected': -2.4364349842071533, 'logits/chosen': -2.407194137573242, 'epoch': 1.33}\n",
            "{'loss': 0.5952, 'grad_norm': 1.488830327987671, 'learning_rate': 3.142859907420615e-06, 'rewards/chosen': 0.25621962547302246, 'rewards/rejected': 0.02928219363093376, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.2269374579191208, 'logps/rejected': -145.35365295410156, 'logps/chosen': -161.74501037597656, 'logits/rejected': -2.490595817565918, 'logits/chosen': -2.4402880668640137, 'epoch': 1.42}\n",
            "{'loss': 0.6086, 'grad_norm': 2.150770425796509, 'learning_rate': 2.8885173136805126e-06, 'rewards/chosen': 0.13434335589408875, 'rewards/rejected': -0.06043384224176407, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.1947772055864334, 'logps/rejected': -132.27882385253906, 'logps/chosen': -146.46566772460938, 'logits/rejected': -2.537461757659912, 'logits/chosen': -2.4924309253692627, 'epoch': 1.51}\n",
            "{'loss': 0.585, 'grad_norm': 2.1981141567230225, 'learning_rate': 2.629974185404951e-06, 'rewards/chosen': 0.20502209663391113, 'rewards/rejected': -0.056472472846508026, 'rewards/accuracies': 0.875, 'rewards/margins': 0.26149457693099976, 'logps/rejected': -136.81497192382812, 'logps/chosen': -149.94363403320312, 'logits/rejected': -2.512640953063965, 'logits/chosen': -2.462644338607788, 'epoch': 1.6}\n",
            "{'loss': 0.5897, 'grad_norm': 1.5787512063980103, 'learning_rate': 2.3700258145950495e-06, 'rewards/chosen': 0.23205307126045227, 'rewards/rejected': -0.02066388726234436, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.25271695852279663, 'logps/rejected': -127.4290542602539, 'logps/chosen': -146.154052734375, 'logits/rejected': -2.472705602645874, 'logits/chosen': -2.442488193511963, 'epoch': 1.69}\n",
            "{'loss': 0.5857, 'grad_norm': 1.6281256675720215, 'learning_rate': 2.1114826863194882e-06, 'rewards/chosen': 0.2725091278553009, 'rewards/rejected': 0.014742428436875343, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.2577666640281677, 'logps/rejected': -135.3296356201172, 'logps/chosen': -154.20571899414062, 'logits/rejected': -2.620394229888916, 'logits/chosen': -2.5814576148986816, 'epoch': 1.78}\n",
            "{'loss': 0.5737, 'grad_norm': 1.7402122020721436, 'learning_rate': 1.8571400925793855e-06, 'rewards/chosen': 0.20870527625083923, 'rewards/rejected': -0.07706569135189056, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 0.2857710123062134, 'logps/rejected': -126.66725158691406, 'logps/chosen': -138.37698364257812, 'logits/rejected': -2.4967663288116455, 'logits/chosen': -2.4409677982330322, 'epoch': 1.87}\n",
            "{'loss': 0.5452, 'grad_norm': 1.9155288934707642, 'learning_rate': 1.6097479104361328e-06, 'rewards/chosen': 0.22495010495185852, 'rewards/rejected': -0.14444252848625183, 'rewards/accuracies': 0.875, 'rewards/margins': 0.36939260363578796, 'logps/rejected': -153.0707244873047, 'logps/chosen': -170.60423278808594, 'logits/rejected': -2.501065492630005, 'logits/chosen': -2.4751944541931152, 'epoch': 1.96}\n",
            "{'loss': 0.5696, 'grad_norm': 1.6740156412124634, 'learning_rate': 1.3719808711521573e-06, 'rewards/chosen': 0.2452823668718338, 'rewards/rejected': -0.06359170377254486, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.30887407064437866, 'logps/rejected': -110.85859680175781, 'logps/chosen': -123.41435241699219, 'logits/rejected': -2.554962396621704, 'logits/chosen': -2.4947783946990967, 'epoch': 2.04}\n",
            "{'loss': 0.5267, 'grad_norm': 1.750775694847107, 'learning_rate': 1.1464096417858821e-06, 'rewards/chosen': 0.3029302954673767, 'rewards/rejected': -0.1195923238992691, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 0.422522634267807, 'logps/rejected': -132.75584411621094, 'logps/chosen': -148.8316192626953, 'logits/rejected': -2.5563807487487793, 'logits/chosen': -2.515772581100464, 'epoch': 2.13}\n",
            "{'loss': 0.541, 'grad_norm': 2.0030622482299805, 'learning_rate': 9.354730318981561e-07, 'rewards/chosen': 0.2865408957004547, 'rewards/rejected': -0.11049344390630722, 'rewards/accuracies': 0.875, 'rewards/margins': 0.39703434705734253, 'logps/rejected': -150.9096221923828, 'logps/chosen': -167.35516357421875, 'logits/rejected': -2.4672560691833496, 'logits/chosen': -2.433194637298584, 'epoch': 2.22}\n",
            "{'loss': 0.5611, 'grad_norm': 1.5457226037979126, 'learning_rate': 7.414516258630245e-07, 'rewards/chosen': 0.22738555073738098, 'rewards/rejected': -0.08509000390768051, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 0.3124755620956421, 'logps/rejected': -134.515869140625, 'logps/chosen': -151.32241821289062, 'logits/rejected': -2.4874749183654785, 'logits/chosen': -2.4421427249908447, 'epoch': 2.31}\n",
            "{'loss': 0.55, 'grad_norm': 1.6726208925247192, 'learning_rate': 5.664431258625305e-07, 'rewards/chosen': 0.3444058895111084, 'rewards/rejected': -0.03152905032038689, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.375934898853302, 'logps/rejected': -127.82231140136719, 'logps/chosen': -143.74557495117188, 'logits/rejected': -2.4819960594177246, 'logits/chosen': -2.4317469596862793, 'epoch': 2.4}\n",
            "{'loss': 0.5029, 'grad_norm': 1.8608403205871582, 'learning_rate': 4.123396721497977e-07, 'rewards/chosen': 0.2959161698818207, 'rewards/rejected': -0.1996818333864212, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 0.4955979883670807, 'logps/rejected': -149.56460571289062, 'logps/chosen': -164.52001953125, 'logits/rejected': -2.5127644538879395, 'logits/chosen': -2.4584450721740723, 'epoch': 2.49}\n",
            "{'loss': 0.5339, 'grad_norm': 2.0404281616210938, 'learning_rate': 2.8080738578703054e-07, 'rewards/chosen': 0.18952810764312744, 'rewards/rejected': -0.22477987408638, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 0.41430798172950745, 'logps/rejected': -134.80824279785156, 'logps/chosen': -146.57046508789062, 'logits/rejected': -2.5742833614349365, 'logits/chosen': -2.539754867553711, 'epoch': 2.58}\n",
            "{'loss': 0.5336, 'grad_norm': 1.7123146057128906, 'learning_rate': 1.7326835503629542e-07, 'rewards/chosen': 0.29412907361984253, 'rewards/rejected': -0.11292456090450287, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 0.4070536196231842, 'logps/rejected': -122.31147766113281, 'logps/chosen': -140.95211791992188, 'logits/rejected': -2.504028797149658, 'logits/chosen': -2.450653076171875, 'epoch': 2.67}\n",
            "{'loss': 0.5552, 'grad_norm': 1.9734177589416504, 'learning_rate': 9.088526016092142e-08, 'rewards/chosen': 0.2658311426639557, 'rewards/rejected': -0.07347895950078964, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 0.33931007981300354, 'logps/rejected': -122.5222396850586, 'logps/chosen': -134.2514190673828, 'logits/rejected': -2.5493783950805664, 'logits/chosen': -2.4916858673095703, 'epoch': 2.76}\n",
            "{'loss': 0.5055, 'grad_norm': 1.6325236558914185, 'learning_rate': 3.4548802869627806e-08, 'rewards/chosen': 0.38169974088668823, 'rewards/rejected': -0.08615829795598984, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 0.4678580164909363, 'logps/rejected': -155.8160858154297, 'logps/chosen': -169.53627014160156, 'logits/rejected': -2.582771062850952, 'logits/chosen': -2.5248794555664062, 'epoch': 2.84}\n",
            "{'loss': 0.5412, 'grad_norm': 1.553223967552185, 'learning_rate': 4.868076312512515e-09, 'rewards/chosen': 0.3042042851448059, 'rewards/rejected': -0.10847330093383789, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.4126775860786438, 'logps/rejected': -147.55641174316406, 'logps/chosen': -160.96719360351562, 'logits/rejected': -2.517404317855835, 'logits/chosen': -2.4811573028564453, 'epoch': 2.93}\n",
            "100% 336/336 [1:11:28<00:00, 11.97s/it][INFO|trainer.py:3675] 2024-09-15 20:37:45,983 >> Saving model checkpoint to /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/checkpoint-336\n",
            "[INFO|configuration_utils.py:672] 2024-09-15 20:37:46,519 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-09-15 20:37:46,519 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-09-15 20:37:46,521 >> Model config Qwen2VLConfig {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3584,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 18944,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 28,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 152064\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2650] 2024-09-15 20:37:46,686 >> tokenizer config file saved in /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/checkpoint-336/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2659] 2024-09-15 20:37:46,687 >> Special tokens file saved in /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/checkpoint-336/special_tokens_map.json\n",
            "[INFO|image_processing_base.py:258] 2024-09-15 20:37:47,170 >> Image processor saved in /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/checkpoint-336/preprocessor_config.json\n",
            "[INFO|trainer.py:2475] 2024-09-15 20:37:47,170 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 4289.8038, 'train_samples_per_second': 0.629, 'train_steps_per_second': 0.078, 'train_loss': 0.6052621212743577, 'epoch': 2.99}\n",
            "100% 336/336 [1:11:29<00:00, 12.77s/it]\n",
            "[INFO|image_processing_base.py:258] 2024-09-15 20:37:47,173 >> Image processor saved in /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/preprocessor_config.json\n",
            "[INFO|trainer.py:3675] 2024-09-15 20:37:47,173 >> Saving model checkpoint to /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo\n",
            "[INFO|configuration_utils.py:672] 2024-09-15 20:37:47,681 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/3ca981c995b0ce691d85d8408216da11ff92f690/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-09-15 20:37:47,682 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-09-15 20:37:47,683 >> Model config Qwen2VLConfig {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 3584,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 18944,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 28,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 152064\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2650] 2024-09-15 20:37:47,866 >> tokenizer config file saved in /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2659] 2024-09-15 20:37:47,866 >> Special tokens file saved in /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =     2.9867\n",
            "  total_flos               = 78842541GF\n",
            "  train_loss               =     0.6053\n",
            "  train_runtime            = 1:11:29.80\n",
            "  train_samples_per_second =      0.629\n",
            "  train_steps_per_second   =      0.078\n",
            "Figure saved at: /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/training_loss.png\n",
            "09/15/2024 20:37:48 - WARNING - llamafactory.extras.ploting - No metric eval_loss to plot.\n",
            "Figure saved at: /conten//drive/MyDrive/saves/qwen2_vl-7b/lora/dpo/training_rewards_accuracies.png\n",
            "[INFO|trainer.py:3991] 2024-09-15 20:37:48,457 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:3993] 2024-09-15 20:37:48,458 >>   Num examples = 100\n",
            "[INFO|trainer.py:3996] 2024-09-15 20:37:48,458 >>   Batch size = 1\n",
            "100% 100/100 [01:35<00:00,  1.05it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =     2.9867\n",
            "  eval_logits/chosen      =    -2.4408\n",
            "  eval_logits/rejected    =    -2.4866\n",
            "  eval_logps/chosen       =   -144.349\n",
            "  eval_logps/rejected     =  -121.4663\n",
            "  eval_loss               =     0.5431\n",
            "  eval_rewards/accuracies =       0.86\n",
            "  eval_rewards/chosen     =     0.3029\n",
            "  eval_rewards/margins    =     0.3753\n",
            "  eval_rewards/rejected   =    -0.0724\n",
            "  eval_runtime            = 0:01:36.22\n",
            "  eval_samples_per_second =      1.039\n",
            "  eval_steps_per_second   =      1.039\n",
            "[INFO|modelcard.py:449] 2024-09-15 20:39:24,683 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/saves/qwen2_vl-7b/lora/dpo"
      ],
      "metadata": {
        "id": "YXzCwBt4bJbY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /conten/drive/MyDrive/saves/qwen2_vl-7b/lora/dpo /content/drive/MyDrive/saves/qwen2_vl-7b/lora/dpo"
      ],
      "metadata": {
        "id": "yGWOD6IbG4_t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference using the fine tuned model"
      ],
      "metadata": {
        "id": "vTrcdzoHQZiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llamafactory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "233jrHTfaa7K",
        "outputId": "0a76b77e-3e6a-4774-8318-692e02f8f7e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llamafactory in /usr/local/lib/python3.10/dist-packages (0.9.1.dev0)\n",
            "Requirement already satisfied: transformers<=4.45.0,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (4.45.0.dev0)\n",
            "Requirement already satisfied: datasets<=2.21.0,>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (2.21.0)\n",
            "Requirement already satisfied: accelerate<=0.34.2,>=0.30.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.34.2)\n",
            "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.12.0)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.9.6)\n",
            "Requirement already satisfied: gradio>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (4.44.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory) (1.13.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.1.99)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.7.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory) (3.20.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.30.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory) (2.9.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.114.2)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/dist-packages (from llamafactory) (2.1.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (3.7.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llamafactory) (0.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory) (2.3.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory) (3.16.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=2.21.0,>=2.16.0->llamafactory) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory) (3.10.5)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (3.7.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (3.10.7)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (9.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (0.6.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory) (2.0.7)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio>=4.0.0->llamafactory) (12.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory) (0.38.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory) (2.23.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory) (0.19.1)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl<=0.9.6,>=0.8.6->llamafactory) (0.8.10)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory) (2.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<=2.21.0,>=2.16.0->llamafactory) (3.3.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (12.6.68)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory) (13.8.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->llamafactory) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llamafactory.chat import ChatModel\n",
        "from llamafactory.extras.misc import torch_gc\n",
        "\n",
        "%cd /content/LLaMA-Factory/\n",
        "\n",
        "args = dict(\n",
        "  model_name_or_path=\"Qwen/Qwen2-VL-7B-Instruct\", # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
        "  adapter_name_or_path=\"/conten/drive/MyDrive/saves/qwen2_vl-7b/lora/dpo\",            # load the saved LoRA adapters\n",
        "  template=\"qwen2_vl\",                     # same to the one in training\n",
        "  finetuning_type=\"lora\",                  # same to the one in training\n",
        "  quantization_bit=4,                    # load 4-bit quantized model\n",
        ")\n",
        "chat_model = ChatModel(args)\n",
        "\n",
        "messages = []\n",
        "print(\"Welcome to the CLI application, use `clear` to remove the history, use `exit` to exit the application.\")\n",
        "while True:\n",
        "  query = input(\"\\nUser: \")\n",
        "  if query.strip() == \"exit\":\n",
        "    break\n",
        "  if query.strip() == \"clear\":\n",
        "    messages = []\n",
        "    torch_gc()\n",
        "    print(\"History has been removed.\")\n",
        "    continue\n",
        "\n",
        "  messages.append({\"role\": \"user\", \"content\": query})\n",
        "  print(\"Assistant: \", end=\"\", flush=True)\n",
        "\n",
        "  response = \"\"\n",
        "  for new_text in chat_model.stream_chat(messages):\n",
        "    print(new_text, end=\"\", flush=True)\n",
        "    response += new_text\n",
        "  print()\n",
        "  messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "torch_gc()"
      ],
      "metadata": {
        "id": "F1pzDQXMPg_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q_JKnQmfaZFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}